{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76a2ce5a",
   "metadata": {},
   "source": [
    "# Stress-Tolerant Seed Varieties Database - Exploratory Data Analysis\n",
    "\n",
    "**Author:** kd475@cornell.edu  \n",
    "**Date:** 2025-08-01  \n",
    "**Purpose:** Comprehensive exploratory data analysis of the stress-tolerant seed varieties database\n",
    "\n",
    "This notebook provides insights into the collected and processed seed variety data, including:\n",
    "- Data quality assessment\n",
    "- Distribution analysis\n",
    "- Stress tolerance patterns\n",
    "- Geographic and temporal trends\n",
    "- Institution and breeding patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3dd8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import json\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Analysis started at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7469bc39",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd7d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final database\n",
    "data_dir = Path(\"../data/final\")\n",
    "csv_file = data_dir / \"stress_tolerant_seed_database.csv\"\n",
    "sqlite_file = data_dir / \"stress_tolerant_seed_database.db\"\n",
    "\n",
    "# Try loading from SQLite first, then CSV\n",
    "if sqlite_file.exists():\n",
    "    print(\"Loading data from SQLite database...\")\n",
    "    conn = sqlite3.connect(sqlite_file)\n",
    "    df = pd.read_sql_query(\"SELECT * FROM stress_tolerant_varieties\", conn)\n",
    "    conn.close()\n",
    "    print(f\"Loaded {len(df)} records from SQLite\")\n",
    "elif csv_file.exists():\n",
    "    print(\"Loading data from CSV file...\")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(f\"Loaded {len(df)} records from CSV\")\n",
    "else:\n",
    "    print(\"No database found. Please run the pipeline first.\")\n",
    "    df = pd.DataFrame()  # Empty dataframe\n",
    "\n",
    "# Display basic information\n",
    "if not df.empty:\n",
    "    print(f\"\\nDataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "else:\n",
    "    print(\"No data to analyze. Please ensure the pipeline has been run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0ad666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "if not df.empty:\n",
    "    print(\"First 5 rows of the dataset:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    print(\"\\nDataset info:\")\n",
    "    print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3e87c3",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7cd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse JSON fields for analysis\n",
    "def parse_json_field(field_value):\n",
    "    \"\"\"Parse JSON field values\"\"\"\n",
    "    if pd.isna(field_value) or field_value == '':\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        if isinstance(field_value, str):\n",
    "            return json.loads(field_value)\n",
    "        elif isinstance(field_value, list):\n",
    "            return field_value\n",
    "        else:\n",
    "            return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "if not df.empty:\n",
    "    # Parse JSON fields\n",
    "    json_fields = ['stressors_tolerated', 'quality_traits', 'genetic_markers', \n",
    "                   'parent_lines', 'adaptation_zones', 'recommended_states', \n",
    "                   'agro_climatic_zones', 'special_features', 'data_sources']\n",
    "    \n",
    "    for field in json_fields:\n",
    "        if field in df.columns:\n",
    "            df[field] = df[field].apply(parse_json_field)\n",
    "            print(f\"Parsed {field}\")\n",
    "    \n",
    "    print(\"\\nJSON fields parsed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc945207",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    print(\"=== DATA QUALITY ASSESSMENT ===\")\n",
    "    \n",
    "    # Missing values analysis\n",
    "    print(\"\\nMissing Values Analysis:\")\n",
    "    missing_stats = df.isnull().sum().sort_values(ascending=False)\n",
    "    missing_pct = (missing_stats / len(df) * 100).round(2)\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing_Count': missing_stats,\n",
    "        'Missing_Percentage': missing_pct\n",
    "    })\n",
    "    \n",
    "    display(missing_df[missing_df['Missing_Count'] > 0])\n",
    "    \n",
    "    # Data completeness distribution\n",
    "    if 'data_completeness_score' in df.columns:\n",
    "        print(\"\\nData Completeness Score Distribution:\")\n",
    "        print(df['data_completeness_score'].describe())\n",
    "    \n",
    "    # Quality flag distribution\n",
    "    if 'quality_flag' in df.columns:\n",
    "        print(\"\\nQuality Flag Distribution:\")\n",
    "        print(df['quality_flag'].value_counts())\n",
    "    \n",
    "    # Confidence level distribution\n",
    "    if 'confidence_level' in df.columns:\n",
    "        print(\"\\nConfidence Level Distribution:\")\n",
    "        print(df['confidence_level'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870ec41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data quality\n",
    "if not df.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Data completeness distribution\n",
    "    if 'data_completeness_score' in df.columns:\n",
    "        axes[0, 0].hist(df['data_completeness_score'], bins=20, alpha=0.7, color='skyblue')\n",
    "        axes[0, 0].set_title('Data Completeness Score Distribution')\n",
    "        axes[0, 0].set_xlabel('Completeness Score')\n",
    "        axes[0, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Quality flag distribution\n",
    "    if 'quality_flag' in df.columns:\n",
    "        quality_counts = df['quality_flag'].value_counts()\n",
    "        axes[0, 1].pie(quality_counts.values, labels=quality_counts.index, autopct='%1.1f%%')\n",
    "        axes[0, 1].set_title('Quality Flag Distribution')\n",
    "    \n",
    "    # Confidence level distribution\n",
    "    if 'confidence_level' in df.columns:\n",
    "        conf_counts = df['confidence_level'].value_counts()\n",
    "        axes[1, 0].bar(conf_counts.index, conf_counts.values, color=['green', 'orange', 'red'])\n",
    "        axes[1, 0].set_title('Confidence Level Distribution')\n",
    "        axes[1, 0].set_ylabel('Count')\n",
    "    \n",
    "    # Missing values heatmap\n",
    "    missing_matrix = df.isnull().astype(int)\n",
    "    sns.heatmap(missing_matrix.corr(), annot=True, cmap='RdYlBu_r', ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Missing Values Correlation')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dbee63",
   "metadata": {},
   "source": [
    "## 4. Basic Statistics and Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41584a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    print(\"=== BASIC STATISTICS ===\")\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(f\"Total varieties: {len(df)}\")\n",
    "    print(f\"Unique varieties: {df['variety_name'].nunique()}\")\n",
    "    print(f\"Unique crops: {df['crop_type'].nunique()}\")\n",
    "    print(f\"Unique institutions: {df['breeding_institution'].nunique()}\")\n",
    "    \n",
    "    # Crop type distribution\n",
    "    print(\"\\nCrop Type Distribution:\")\n",
    "    crop_dist = df['crop_type'].value_counts()\n",
    "    print(crop_dist)\n",
    "    \n",
    "    # Year of release statistics\n",
    "    if 'year_of_release' in df.columns:\n",
    "        year_stats = df['year_of_release'].describe()\n",
    "        print(\"\\nYear of Release Statistics:\")\n",
    "        print(year_stats)\n",
    "    \n",
    "    # Maturity days statistics\n",
    "    if 'maturity_days' in df.columns:\n",
    "        maturity_stats = df['maturity_days'].describe()\n",
    "        print(\"\\nMaturity Days Statistics:\")\n",
    "        print(maturity_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12483a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize basic distributions\n",
    "if not df.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Crop type distribution\n",
    "    crop_counts = df['crop_type'].value_counts()\n",
    "    axes[0, 0].pie(crop_counts.values, labels=crop_counts.index, autopct='%1.1f%%')\n",
    "    axes[0, 0].set_title('Distribution by Crop Type')\n",
    "    \n",
    "    # Year of release distribution\n",
    "    if 'year_of_release' in df.columns:\n",
    "        df['year_of_release'].hist(bins=20, ax=axes[0, 1], alpha=0.7, color='lightgreen')\n",
    "        axes[0, 1].set_title('Distribution by Year of Release')\n",
    "        axes[0, 1].set_xlabel('Year')\n",
    "        axes[0, 1].set_ylabel('Number of Varieties')\n",
    "    \n",
    "    # Top institutions\n",
    "    top_institutions = df['breeding_institution'].value_counts().head(10)\n",
    "    axes[1, 0].barh(range(len(top_institutions)), top_institutions.values)\n",
    "    axes[1, 0].set_yticks(range(len(top_institutions)))\n",
    "    axes[1, 0].set_yticklabels([inst[:30] + '...' if len(inst) > 30 else inst for inst in top_institutions.index])\n",
    "    axes[1, 0].set_title('Top 10 Breeding Institutions')\n",
    "    axes[1, 0].set_xlabel('Number of Varieties')\n",
    "    \n",
    "    # Maturity days distribution\n",
    "    if 'maturity_days' in df.columns:\n",
    "        df['maturity_days'].hist(bins=15, ax=axes[1, 1], alpha=0.7, color='salmon')\n",
    "        axes[1, 1].set_title('Distribution by Maturity Days')\n",
    "        axes[1, 1].set_xlabel('Days to Maturity')\n",
    "        axes[1, 1].set_ylabel('Number of Varieties')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc389ca",
   "metadata": {},
   "source": [
    "## 5. Stress Tolerance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a82e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty and 'stressors_tolerated' in df.columns:\n",
    "    print(\"=== STRESS TOLERANCE ANALYSIS ===\")\n",
    "    \n",
    "    # Extract all stress tolerances\n",
    "    all_stresses = []\n",
    "    stress_variety_count = 0\n",
    "    \n",
    "    for stresses in df['stressors_tolerated']:\n",
    "        if isinstance(stresses, list) and len(stresses) > 0:\n",
    "            all_stresses.extend(stresses)\n",
    "            stress_variety_count += 1\n",
    "    \n",
    "    print(f\"Varieties with stress tolerance information: {stress_variety_count}\")\n",
    "    print(f\"Total stress tolerance entries: {len(all_stresses)}\")\n",
    "    \n",
    "    # Count stress tolerances\n",
    "    stress_counter = Counter(all_stresses)\n",
    "    stress_df = pd.DataFrame.from_dict(stress_counter, orient='index', columns=['Count'])\n",
    "    stress_df = stress_df.sort_values('Count', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop Stress Tolerances:\")\n",
    "    print(stress_df.head(15))\n",
    "    \n",
    "    # Stress tolerance per crop\n",
    "    stress_crop_data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        crop = row['crop_type']\n",
    "        stresses = row['stressors_tolerated']\n",
    "        if isinstance(stresses, list):\n",
    "            for stress in stresses:\n",
    "                stress_crop_data.append({'Crop': crop, 'Stress': stress})\n",
    "    \n",
    "    if stress_crop_data:\n",
    "        stress_crop_df = pd.DataFrame(stress_crop_data)\n",
    "        print(\"\\nStress tolerance by crop type:\")\n",
    "        stress_crop_crosstab = pd.crosstab(stress_crop_df['Stress'], stress_crop_df['Crop'])\n",
    "        print(stress_crop_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize stress tolerance analysis\n",
    "if not df.empty and 'stressors_tolerated' in df.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Top stress tolerances\n",
    "    if len(stress_df) > 0:\n",
    "        top_stresses = stress_df.head(15)\n",
    "        axes[0, 0].barh(range(len(top_stresses)), top_stresses['Count'])\n",
    "        axes[0, 0].set_yticks(range(len(top_stresses)))\n",
    "        axes[0, 0].set_yticklabels(top_stresses.index)\n",
    "        axes[0, 0].set_title('Top 15 Stress Tolerances')\n",
    "        axes[0, 0].set_xlabel('Number of Varieties')\n",
    "    \n",
    "    # Number of stress tolerances per variety\n",
    "    stress_counts_per_variety = df['stressors_tolerated'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "    axes[0, 1].hist(stress_counts_per_variety, bins=range(0, max(stress_counts_per_variety)+2), \n",
    "                    alpha=0.7, color='lightcoral')\n",
    "    axes[0, 1].set_title('Number of Stress Tolerances per Variety')\n",
    "    axes[0, 1].set_xlabel('Number of Stress Tolerances')\n",
    "    axes[0, 1].set_ylabel('Number of Varieties')\n",
    "    \n",
    "    # Stress tolerance heatmap by crop (if data exists)\n",
    "    if 'stress_crop_crosstab' in locals() and not stress_crop_crosstab.empty:\n",
    "        # Select top stresses and crops for better visualization\n",
    "        top_stresses_for_heatmap = stress_crop_crosstab.sum(axis=1).sort_values(ascending=False).head(10)\n",
    "        top_crops_for_heatmap = stress_crop_crosstab.sum(axis=0).sort_values(ascending=False).head(8)\n",
    "        \n",
    "        heatmap_data = stress_crop_crosstab.loc[top_stresses_for_heatmap.index, top_crops_for_heatmap.index]\n",
    "        \n",
    "        sns.heatmap(heatmap_data, annot=True, cmap='YlOrRd', ax=axes[1, 0])\n",
    "        axes[1, 0].set_title('Stress Tolerance by Crop Type (Top 10 x Top 8)')\n",
    "        axes[1, 0].set_xlabel('Crop Type')\n",
    "        axes[1, 0].set_ylabel('Stress Tolerance')\n",
    "    \n",
    "    # Pie chart of varieties with/without stress tolerance info\n",
    "    has_stress_info = sum(1 for x in df['stressors_tolerated'] if isinstance(x, list) and len(x) > 0)\n",
    "    no_stress_info = len(df) - has_stress_info\n",
    "    \n",
    "    stress_info_data = [has_stress_info, no_stress_info]\n",
    "    stress_info_labels = ['With Stress Info', 'Without Stress Info']\n",
    "    \n",
    "    axes[1, 1].pie(stress_info_data, labels=stress_info_labels, autopct='%1.1f%%', \n",
    "                   colors=['lightgreen', 'lightgray'])\n",
    "    axes[1, 1].set_title('Varieties with Stress Tolerance Information')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860a01ff",
   "metadata": {},
   "source": [
    "## 6. Geographic and Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23348175",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    print(\"=== GEOGRAPHIC AND TEMPORAL ANALYSIS ===\")\n",
    "    \n",
    "    # State-wise distribution\n",
    "    if 'recommended_states' in df.columns:\n",
    "        all_states = []\n",
    "        for states in df['recommended_states']:\n",
    "            if isinstance(states, list):\n",
    "                all_states.extend(states)\n",
    "        \n",
    "        if all_states:\n",
    "            state_counter = Counter(all_states)\n",
    "            state_df = pd.DataFrame.from_dict(state_counter, orient='index', columns=['Count'])\n",
    "            state_df = state_df.sort_values('Count', ascending=False)\n",
    "            \n",
    "            print(\"\\nTop 15 Recommended States:\")\n",
    "            print(state_df.head(15))\n",
    "    \n",
    "    # Temporal trends\n",
    "    if 'year_of_release' in df.columns:\n",
    "        year_trends = df['year_of_release'].value_counts().sort_index()\n",
    "        print(\"\\nVarieties released by decade:\")\n",
    "        \n",
    "        # Group by decades\n",
    "        decades = {}\n",
    "        for year, count in year_trends.items():\n",
    "            if pd.notna(year):\n",
    "                decade = f\"{int(year)//10*10}s\"\n",
    "                decades[decade] = decades.get(decade, 0) + count\n",
    "        \n",
    "        for decade, count in sorted(decades.items()):\n",
    "            print(f\"{decade}: {count}\")\n",
    "    \n",
    "    # Crop-year analysis\n",
    "    if 'year_of_release' in df.columns and 'crop_type' in df.columns:\n",
    "        crop_year_data = df.groupby(['crop_type', 'year_of_release']).size().reset_index(name='count')\n",
    "        print(\"\\nRecent trends (2010 onwards) by crop:\")\n",
    "        recent_data = crop_year_data[crop_year_data['year_of_release'] >= 2010]\n",
    "        recent_summary = recent_data.groupby('crop_type')['count'].sum().sort_values(ascending=False)\n",
    "        print(recent_summary.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c5c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize geographic and temporal patterns\n",
    "if not df.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Top recommended states\n",
    "    if 'state_df' in locals() and len(state_df) > 0:\n",
    "        top_states = state_df.head(15)\n",
    "        axes[0, 0].barh(range(len(top_states)), top_states['Count'])\n",
    "        axes[0, 0].set_yticks(range(len(top_states)))\n",
    "        axes[0, 0].set_yticklabels(top_states.index)\n",
    "        axes[0, 0].set_title('Top 15 Recommended States')\n",
    "        axes[0, 0].set_xlabel('Number of Varieties')\n",
    "    \n",
    "    # Year of release trend\n",
    "    if 'year_of_release' in df.columns:\n",
    "        year_counts = df['year_of_release'].value_counts().sort_index()\n",
    "        axes[0, 1].plot(year_counts.index, year_counts.values, marker='o', linewidth=2)\n",
    "        axes[0, 1].set_title('Varieties Released by Year')\n",
    "        axes[0, 1].set_xlabel('Year')\n",
    "        axes[0, 1].set_ylabel('Number of Varieties')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Decade distribution\n",
    "    if 'decades' in locals():\n",
    "        decade_names = list(decades.keys())\n",
    "        decade_counts = list(decades.values())\n",
    "        axes[1, 0].bar(decade_names, decade_counts, alpha=0.7, color='skyblue')\n",
    "        axes[1, 0].set_title('Varieties Released by Decade')\n",
    "        axes[1, 0].set_xlabel('Decade')\n",
    "        axes[1, 0].set_ylabel('Number of Varieties')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Recent trends by crop (2010 onwards)\n",
    "    if 'recent_summary' in locals() and len(recent_summary) > 0:\n",
    "        top_recent_crops = recent_summary.head(10)\n",
    "        axes[1, 1].pie(top_recent_crops.values, labels=top_recent_crops.index, autopct='%1.1f%%')\n",
    "        axes[1, 1].set_title('Recent Varieties by Crop (2010+)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac85c318",
   "metadata": {},
   "source": [
    "## 7. Institution and Breeding Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7916e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    print(\"=== INSTITUTION AND BREEDING ANALYSIS ===\")\n",
    "    \n",
    "    # Top breeding institutions\n",
    "    inst_counts = df['breeding_institution'].value_counts()\n",
    "    print(\"\\nTop 15 Breeding Institutions:\")\n",
    "    print(inst_counts.head(15))\n",
    "    \n",
    "    # Institution-crop specialization\n",
    "    if 'crop_type' in df.columns:\n",
    "        inst_crop_analysis = df.groupby(['breeding_institution', 'crop_type']).size().reset_index(name='count')\n",
    "        \n",
    "        # Find institutions with highest diversity (number of different crops)\n",
    "        inst_diversity = inst_crop_analysis.groupby('breeding_institution')['crop_type'].nunique().sort_values(ascending=False)\n",
    "        print(\"\\nInstitutions with highest crop diversity:\")\n",
    "        print(inst_diversity.head(10))\n",
    "        \n",
    "        # Find crop specialists (institutions focusing on specific crops)\n",
    "        print(\"\\nTop specialists by crop:\")\n",
    "        for crop in df['crop_type'].value_counts().head(5).index:\n",
    "            crop_specialists = df[df['crop_type'] == crop]['breeding_institution'].value_counts().head(3)\n",
    "            print(f\"\\n{crop}:\")\n",
    "            for inst, count in crop_specialists.items():\n",
    "                print(f\"  {inst}: {count} varieties\")\n",
    "    \n",
    "    # Quality traits analysis\n",
    "    if 'quality_traits' in df.columns:\n",
    "        all_quality_traits = []\n",
    "        for traits in df['quality_traits']:\n",
    "            if isinstance(traits, list):\n",
    "                all_quality_traits.extend(traits)\n",
    "        \n",
    "        if all_quality_traits:\n",
    "            quality_counter = Counter(all_quality_traits)\n",
    "            quality_df = pd.DataFrame.from_dict(quality_counter, orient='index', columns=['Count'])\n",
    "            quality_df = quality_df.sort_values('Count', ascending=False)\n",
    "            \n",
    "            print(\"\\nTop 15 Quality Traits:\")\n",
    "            print(quality_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22885ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize institution and breeding patterns\n",
    "if not df.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Top institutions\n",
    "    top_institutions = inst_counts.head(15)\n",
    "    axes[0, 0].barh(range(len(top_institutions)), top_institutions.values)\n",
    "    axes[0, 0].set_yticks(range(len(top_institutions)))\n",
    "    # Truncate long institution names for display\n",
    "    truncated_names = [name[:40] + '...' if len(name) > 40 else name for name in top_institutions.index]\n",
    "    axes[0, 0].set_yticklabels(truncated_names)\n",
    "    axes[0, 0].set_title('Top 15 Breeding Institutions')\n",
    "    axes[0, 0].set_xlabel('Number of Varieties')\n",
    "    \n",
    "    # Institution diversity\n",
    "    if 'inst_diversity' in locals():\n",
    "        top_diverse = inst_diversity.head(10)\n",
    "        axes[0, 1].bar(range(len(top_diverse)), top_diverse.values, alpha=0.7, color='lightgreen')\n",
    "        axes[0, 1].set_xticks(range(len(top_diverse)))\n",
    "        # Truncate institution names for x-axis\n",
    "        truncated_diverse_names = [name[:15] + '...' if len(name) > 15 else name for name in top_diverse.index]\n",
    "        axes[0, 1].set_xticklabels(truncated_diverse_names, rotation=45, ha='right')\n",
    "        axes[0, 1].set_title('Institution Crop Diversity')\n",
    "        axes[0, 1].set_ylabel('Number of Different Crops')\n",
    "    \n",
    "    # Quality traits\n",
    "    if 'quality_df' in locals() and len(quality_df) > 0:\n",
    "        top_quality = quality_df.head(15)\n",
    "        axes[1, 0].barh(range(len(top_quality)), top_quality['Count'])\n",
    "        axes[1, 0].set_yticks(range(len(top_quality)))\n",
    "        axes[1, 0].set_yticklabels(top_quality.index)\n",
    "        axes[1, 0].set_title('Top 15 Quality Traits')\n",
    "        axes[1, 0].set_xlabel('Number of Varieties')\n",
    "    \n",
    "    # Number of quality traits per variety\n",
    "    if 'quality_traits' in df.columns:\n",
    "        quality_counts_per_variety = df['quality_traits'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "        axes[1, 1].hist(quality_counts_per_variety, bins=range(0, max(quality_counts_per_variety)+2), \n",
    "                        alpha=0.7, color='lightpink')\n",
    "        axes[1, 1].set_title('Number of Quality Traits per Variety')\n",
    "        axes[1, 1].set_xlabel('Number of Quality Traits')\n",
    "        axes[1, 1].set_ylabel('Number of Varieties')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afee2ed",
   "metadata": {},
   "source": [
    "## 8. Advanced Analytics and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c62ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    print(\"=== ADVANCED ANALYTICS AND INSIGHTS ===\")\n",
    "    \n",
    "    # Multi-stress tolerant varieties\n",
    "    stress_counts = df['stressors_tolerated'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "    multi_stress_varieties = df[stress_counts >= 3]\n",
    "    \n",
    "    print(f\"\\nVarieties with 3+ stress tolerances: {len(multi_stress_varieties)}\")\n",
    "    if len(multi_stress_varieties) > 0:\n",
    "        print(\"\\nTop multi-stress tolerant varieties:\")\n",
    "        for idx, row in multi_stress_varieties.head(10).iterrows():\n",
    "            stresses = ', '.join(row['stressors_tolerated'])\n",
    "            print(f\"  {row['variety_name']} ({row['crop_type']}): {stresses}\")\n",
    "    \n",
    "    # Correlation analysis\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_columns) > 1:\n",
    "        correlation_matrix = df[numeric_columns].corr()\n",
    "        print(\"\\nCorrelation analysis (significant correlations):\")\n",
    "        \n",
    "        # Find strong correlations (> 0.5 or < -0.5)\n",
    "        strong_correlations = []\n",
    "        for i in range(len(correlation_matrix.columns)):\n",
    "            for j in range(i+1, len(correlation_matrix.columns)):\n",
    "                corr_value = correlation_matrix.iloc[i, j]\n",
    "                if abs(corr_value) > 0.5 and not np.isnan(corr_value):\n",
    "                    strong_correlations.append((\n",
    "                        correlation_matrix.columns[i],\n",
    "                        correlation_matrix.columns[j],\n",
    "                        corr_value\n",
    "                    ))\n",
    "        \n",
    "        if strong_correlations:\n",
    "            for col1, col2, corr in strong_correlations:\n",
    "                print(f\"  {col1} vs {col2}: {corr:.3f}\")\n",
    "        else:\n",
    "            print(\"  No strong correlations found\")\n",
    "    \n",
    "    # Data completeness by source\n",
    "    if 'data_sources' in df.columns and 'data_completeness_score' in df.columns:\n",
    "        source_completeness = []\n",
    "        for idx, row in df.iterrows():\n",
    "            sources = row['data_sources']\n",
    "            completeness = row['data_completeness_score']\n",
    "            if isinstance(sources, list) and pd.notna(completeness):\n",
    "                for source in sources:\n",
    "                    source_completeness.append({\n",
    "                        'source': source,\n",
    "                        'completeness': completeness\n",
    "                    })\n",
    "        \n",
    "        if source_completeness:\n",
    "            source_comp_df = pd.DataFrame(source_completeness)\n",
    "            avg_completeness_by_source = source_comp_df.groupby('source')['completeness'].mean().sort_values(ascending=False)\n",
    "            print(\"\\nAverage data completeness by source:\")\n",
    "            print(avg_completeness_by_source.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02520663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced visualizations\n",
    "if not df.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Multi-stress tolerance distribution\n",
    "    stress_count_dist = stress_counts.value_counts().sort_index()\n",
    "    axes[0, 0].bar(stress_count_dist.index, stress_count_dist.values, alpha=0.7, color='mediumpurple')\n",
    "    axes[0, 0].set_title('Distribution of Stress Tolerance Count')\n",
    "    axes[0, 0].set_xlabel('Number of Stress Tolerances')\n",
    "    axes[0, 0].set_ylabel('Number of Varieties')\n",
    "    \n",
    "    # Correlation heatmap (if numeric data available)\n",
    "    if len(numeric_columns) > 1:\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[0, 1])\n",
    "        axes[0, 1].set_title('Correlation Matrix')\n",
    "    \n",
    "    # Data completeness by crop type\n",
    "    if 'data_completeness_score' in df.columns:\n",
    "        completeness_by_crop = df.groupby('crop_type')['data_completeness_score'].mean().sort_values(ascending=False)\n",
    "        axes[1, 0].bar(range(len(completeness_by_crop)), completeness_by_crop.values, alpha=0.7, color='orange')\n",
    "        axes[1, 0].set_xticks(range(len(completeness_by_crop)))\n",
    "        axes[1, 0].set_xticklabels(completeness_by_crop.index, rotation=45, ha='right')\n",
    "        axes[1, 0].set_title('Average Data Completeness by Crop Type')\n",
    "        axes[1, 0].set_ylabel('Completeness Score')\n",
    "    \n",
    "    # Maturity vs Year scatter (if both available)\n",
    "    if 'maturity_days' in df.columns and 'year_of_release' in df.columns:\n",
    "        # Remove outliers for better visualization\n",
    "        clean_data = df[(df['maturity_days'] < 300) & (df['year_of_release'] > 1990)]\n",
    "        axes[1, 1].scatter(clean_data['year_of_release'], clean_data['maturity_days'], alpha=0.6)\n",
    "        axes[1, 1].set_title('Maturity Days vs Year of Release')\n",
    "        axes[1, 1].set_xlabel('Year of Release')\n",
    "        axes[1, 1].set_ylabel('Maturity Days')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835510fa",
   "metadata": {},
   "source": [
    "## 9. Summary and Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    print(\"=== SUMMARY ===\")\n",
    "    \n",
    "    print(f\"\\n DATASET OVERVIEW:\")\n",
    "    print(f\"   • Total varieties in database: {len(df):,}\")\n",
    "    print(f\"   • Unique crops covered: {df['crop_type'].nunique()}\")\n",
    "    print(f\"   • Breeding institutions involved: {df['breeding_institution'].nunique()}\")\n",
    "    print(f\"   • Average data completeness: {df['data_completeness_score'].mean():.2f}\")\n",
    "    \n",
    "    print(f\"\\n CROP INSIGHTS:\")\n",
    "    top_crop = df['crop_type'].value_counts().index[0]\n",
    "    top_crop_count = df['crop_type'].value_counts().iloc[0]\n",
    "    print(f\"   • Most represented crop: {top_crop} ({top_crop_count} varieties)\")\n",
    "    print(f\"   • Crop diversity index: {df['crop_type'].nunique() / len(df):.3f}\")\n",
    "    \n",
    "    print(f\"\\n STRESS TOLERANCE INSIGHTS:\")\n",
    "    stress_variety_count = sum(1 for x in df['stressors_tolerated'] if isinstance(x, list) and len(x) > 0)\n",
    "    print(f\"   • Varieties with stress tolerance info: {stress_variety_count} ({stress_variety_count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    if 'stress_df' in locals() and len(stress_df) > 0:\n",
    "        top_stress = stress_df.index[0]\n",
    "        top_stress_count = stress_df.iloc[0, 0]\n",
    "        print(f\"   • Most common stress tolerance: {top_stress} ({top_stress_count} varieties)\")\n",
    "    \n",
    "    multi_stress_count = sum(1 for x in df['stressors_tolerated'] if isinstance(x, list) and len(x) >= 3)\n",
    "    print(f\"   • Multi-stress tolerant varieties (3+): {multi_stress_count}\")\n",
    "    \n",
    "    print(f\"\\n INSTITUTIONAL INSIGHTS:\")\n",
    "    top_institution = df['breeding_institution'].value_counts().index[0]\n",
    "    top_inst_count = df['breeding_institution'].value_counts().iloc[0]\n",
    "    print(f\"   • Most productive institution: {top_institution[:50]}... ({top_inst_count} varieties)\")\n",
    "    \n",
    "    if 'inst_diversity' in locals():\n",
    "        most_diverse = inst_diversity.index[0]\n",
    "        diversity_count = inst_diversity.iloc[0]\n",
    "        print(f\"   • Most diverse institution: {most_diverse[:50]}... ({diversity_count} crops)\")\n",
    "    \n",
    "    print(f\"\\n TEMPORAL INSIGHTS:\")\n",
    "    if 'year_of_release' in df.columns:\n",
    "        recent_varieties = len(df[df['year_of_release'] >= 2010])\n",
    "        print(f\"   • Varieties released since 2010: {recent_varieties}\")\n",
    "        \n",
    "        if recent_varieties > 0:\n",
    "            avg_year = df[df['year_of_release'] >= 1990]['year_of_release'].mean()\n",
    "            print(f\"   • Average release year (1990+): {avg_year:.0f}\")\n",
    "    \n",
    "    print(f\"\\n GEOGRAPHIC INSIGHTS:\")\n",
    "    if 'state_df' in locals() and len(state_df) > 0:\n",
    "        top_state = state_df.index[0]\n",
    "        top_state_count = state_df.iloc[0, 0]\n",
    "        print(f\"   • Most recommended state: {top_state} ({top_state_count} varieties)\")\n",
    "        print(f\"   • States covered: {len(state_df)}\")\n",
    "    \n",
    "    print(f\"\\n DATA QUALITY INSIGHTS:\")\n",
    "    if 'quality_flag' in df.columns:\n",
    "        good_quality = len(df[df['quality_flag'] == 'GOOD'])\n",
    "        print(f\"   • High quality records: {good_quality} ({good_quality/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    if 'confidence_level' in df.columns:\n",
    "        high_confidence = len(df[df['confidence_level'] == 'HIGH'])\n",
    "        print(f\"   • High confidence records: {high_confidence} ({high_confidence/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n RECOMMENDATIONS FOR FURTHER ANALYSIS:\")\n",
    "    print(f\"   • Focus on multi-stress tolerant varieties for climate resilience\")\n",
    "    print(f\"   • Investigate regional adaptation patterns\")\n",
    "    print(f\"   • Analyze breeding institution collaboration networks\")\n",
    "    print(f\"   • Study temporal trends in stress tolerance development\")\n",
    "    print(f\"   • Examine quality trait combinations for market preferences\")\n",
    "    \n",
    "    print(f\"\\n DATABASE GROWTH POTENTIAL:\")\n",
    "    low_completeness = len(df[df['data_completeness_score'] < 0.5])\n",
    "    print(f\"   • Records with improvement potential: {low_completeness}\")\n",
    "    print(f\"   • Opportunity for data enrichment exists in stress tolerance and quality traits\")\n",
    "    \n",
    "else:\n",
    "    print(\"No data available for analysis. Please ensure the pipeline has been executed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
